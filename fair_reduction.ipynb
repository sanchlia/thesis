{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import os\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd \n",
    "\n",
    "from bin.dataset import Dataset\n",
    "from bin.experiment import Experiment\n",
    "from bin.metrics import Metrics\n",
    "\n",
    "from collections import defaultdict\n",
    "\n",
    "from models.LR import Lr\n",
    "from models.reduction import Reduction\n",
    "from models.reweight import Reweight\n",
    "from models.fair_reduction import FairReduction\n",
    "\n",
    "from scipy.special import xlog1py\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import roc_auc_score, f1_score, precision_score, accuracy_score, recall_score\n",
    "from fairlearn.metrics import (\n",
    "    MetricFrame, plot_model_comparison,\n",
    "    selection_rate, demographic_parity_difference, demographic_parity_ratio,\n",
    "    false_positive_rate, false_negative_rate,\n",
    "    false_positive_rate_difference, false_negative_rate_difference,true_positive_rate, \n",
    "    equalized_odds_difference)\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = {\n",
    "    \"FR\": FairReduction\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_config(path):\n",
    "    \"\"\"Reads the config file and returns a dictionary.\"\"\"\n",
    "    try:\n",
    "        with open(path) as f:\n",
    "            config = json.load(f)\n",
    "    except FileNotFoundError:\n",
    "        print(\"Config file not found.\")\n",
    "        config = None\n",
    "    return config\n",
    "\n",
    "def load_csv(path):\n",
    "    \"\"\"Loads the csv file and returns a dataframe.\"\"\"\n",
    "    try:\n",
    "        df = pd.read_csv(path)\n",
    "    except FileNotFoundError:\n",
    "        print(\"CSV file not found.\")\n",
    "        df = None\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "exp_conf = \"configs/adult_noisy.json\"\n",
    "# exp_conf = \"configs/compas_noisy.json\"\n",
    "# exp_conf = \"configs/synthetic_20_noisy.json\"\n",
    "# exp_conf = \"configs/income_noisy.json\"\n",
    "# exp_conf = \"configs/baseline_config.json\"\n",
    "\n",
    "EXP = read_config(exp_conf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "datasets = {}\n",
    "try:\n",
    "    for name, value in EXP.items():\n",
    "        # if name in ['adult_bias_0.1','adult_bias_0.3']: continue\n",
    "        # if name in ['COMPAS_balanced_0.1']: continue\n",
    "        # if not name in ['income_balanced_0.1']: continue\n",
    "        # if name in ['synthetic_20_balanced_0.1']: continue\n",
    "        # print(f\"{name=} and {value=}\")\n",
    "        if (not name in [\n",
    "            'adult_flip_0.3'\n",
    "        ]): continue\n",
    "        datasets[name] = Dataset(value)\n",
    "        datasets[name].calculate_probabilities(\"fair\")\n",
    "        datasets[name].calculate_probabilities(\"emp\")\n",
    "\n",
    "except Exception as e:\n",
    "    print(e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'adult_flip_0.3': <bin.dataset.Dataset at 0x174bf5310>}"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "adult_flip_0.3\n",
      "x1\n",
      "emp\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'e_y_0' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[7], line 47\u001b[0m\n\u001b[1;32m     36\u001b[0m \u001b[39mprint\u001b[39m(w_name)\n\u001b[1;32m     37\u001b[0m \u001b[39m# w_dict = {\u001b[39;00m\n\u001b[1;32m     38\u001b[0m \u001b[39m#     \"weights\": w, \u001b[39;00m\n\u001b[1;32m     39\u001b[0m \u001b[39m#     \"p_y\" : data_obj.p_y,\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     45\u001b[0m \u001b[39m#     \"p_y_s\": data_obj.fair_prob_map[fold]['p_y_s']\u001b[39;00m\n\u001b[1;32m     46\u001b[0m \u001b[39m# }\u001b[39;00m\n\u001b[0;32m---> 47\u001b[0m _model \u001b[39m=\u001b[39m FairReduction()\u001b[39m.\u001b[39;49mfit(x_train, y_train, sv_train, weights \u001b[39m=\u001b[39;49m w)\n\u001b[1;32m     48\u001b[0m y_pred \u001b[39m=\u001b[39m _model\u001b[39m.\u001b[39mpredict(x_test)\n\u001b[1;32m     49\u001b[0m pred_path \u001b[39m=\u001b[39m os\u001b[39m.\u001b[39mpath\u001b[39m.\u001b[39mjoin(base_path, \u001b[39m\"\u001b[39m\u001b[39mfair_reduction\u001b[39m\u001b[39m\"\u001b[39m, data_obj\u001b[39m.\u001b[39mname, data_obj\u001b[39m.\u001b[39mexp_name, \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mFR_\u001b[39m\u001b[39m{\u001b[39;00mw_name\u001b[39m}\u001b[39;00m\u001b[39m\"\u001b[39m, fold)\n",
      "File \u001b[0;32m~/Fair_ML/Projects/thesis/models/fair_reduction.py:23\u001b[0m, in \u001b[0;36mFairReduction.fit\u001b[0;34m(self, X_train, y_train, s_train, weights)\u001b[0m\n\u001b[1;32m     17\u001b[0m learn \u001b[39m=\u001b[39m ExponentiatedGradient(\n\u001b[1;32m     18\u001b[0m LogisticRegression(solver\u001b[39m=\u001b[39m\u001b[39m'\u001b[39m\u001b[39mliblinear\u001b[39m\u001b[39m'\u001b[39m, fit_intercept\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m),\n\u001b[1;32m     19\u001b[0m constraints\u001b[39m=\u001b[39mEqualizedOdds())\n\u001b[1;32m     20\u001b[0m \u001b[39m# learn.fit(X_train, y_train,sensitive_features= s_train)\u001b[39;00m\n\u001b[1;32m     21\u001b[0m \n\u001b[1;32m     22\u001b[0m \u001b[39m# Add support for model with params.\u001b[39;00m\n\u001b[0;32m---> 23\u001b[0m learn\u001b[39m.\u001b[39;49mfit(X_train, y_train,sensitive_features\u001b[39m=\u001b[39;49m s_train, fair_weights \u001b[39m=\u001b[39;49m weights)\n\u001b[1;32m     24\u001b[0m \u001b[39mreturn\u001b[39;00m learn\n",
      "File \u001b[0;32m~/Fair_ML/Projects/thesis/FL08/lib/python3.11/site-packages/fairlearn/reductions/_exponentiated_gradient/exponentiated_gradient.py:168\u001b[0m, in \u001b[0;36mExponentiatedGradient.fit\u001b[0;34m(self, X, y, **kwargs)\u001b[0m\n\u001b[1;32m    165\u001b[0m lambda_EG \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mlambda_vecs_EG_\u001b[39m.\u001b[39mmean(axis\u001b[39m=\u001b[39m\u001b[39m1\u001b[39m)\n\u001b[1;32m    167\u001b[0m \u001b[39m# select classifier according to best_h method\u001b[39;00m\n\u001b[0;32m--> 168\u001b[0m h, h_idx \u001b[39m=\u001b[39m lagrangian\u001b[39m.\u001b[39;49mbest_h(lambda_vec)\n\u001b[1;32m    170\u001b[0m \u001b[39mif\u001b[39;00m t \u001b[39m==\u001b[39m \u001b[39m0\u001b[39m:\n\u001b[1;32m    171\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mnu \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n",
      "File \u001b[0;32m~/Fair_ML/Projects/thesis/FL08/lib/python3.11/site-packages/fairlearn/reductions/_exponentiated_gradient/_lagrangian.py:247\u001b[0m, in \u001b[0;36m_Lagrangian.best_h\u001b[0;34m(self, lambda_vec)\u001b[0m\n\u001b[1;32m    244\u001b[0m     \u001b[39mreturn\u001b[39;00m pred\n\u001b[1;32m    246\u001b[0m h_error \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mobj\u001b[39m.\u001b[39mgamma(h)[\u001b[39m0\u001b[39m]\n\u001b[0;32m--> 247\u001b[0m h_gamma \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mconstraints\u001b[39m.\u001b[39;49mgamma(h)\n\u001b[1;32m    248\u001b[0m h_value \u001b[39m=\u001b[39m h_error \u001b[39m+\u001b[39m h_gamma\u001b[39m.\u001b[39mdot(lambda_vec)\n\u001b[1;32m    250\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mhs\u001b[39m.\u001b[39mempty:\n",
      "File \u001b[0;32m~/Fair_ML/Projects/thesis/FL08/lib/python3.11/site-packages/fairlearn/reductions/_moments/utility_parity.py:284\u001b[0m, in \u001b[0;36mUtilityParity.gamma\u001b[0;34m(self, predictor)\u001b[0m\n\u001b[1;32m    266\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mtags[_PREDICTION] \u001b[39m=\u001b[39m pred\n\u001b[1;32m    267\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mp_y \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m \u001b[39mand\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mp_y_s \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m    268\u001b[0m     \u001b[39m# event index \u001b[39;00m\n\u001b[1;32m    269\u001b[0m     \u001b[39m# event_index_tuple = [('label=0'), ('label=1')]\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    282\u001b[0m     \u001b[39m# n_s = self.tags.groupby('group_id').size()/2\u001b[39;00m\n\u001b[1;32m    283\u001b[0m     \u001b[39m# expect_group_event = expect_group_event['weights']/(n_s * self.p_y_s)\u001b[39;00m\n\u001b[0;32m--> 284\u001b[0m     expect_event, expect_group_event \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mestimate_conditional()\n\u001b[1;32m    285\u001b[0m     upper_bound_diff \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mratio \u001b[39m*\u001b[39m expect_group_event \u001b[39m-\u001b[39m expect_event\n\u001b[1;32m    287\u001b[0m     lower_bound_diff \u001b[39m=\u001b[39m \u001b[39m-\u001b[39mexpect_group_event \u001b[39m+\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mratio \u001b[39m*\u001b[39m expect_event\n",
      "File \u001b[0;32m~/Fair_ML/Projects/thesis/FL08/lib/python3.11/site-packages/fairlearn/reductions/_moments/utility_parity.py:243\u001b[0m, in \u001b[0;36mUtilityParity.estimate_conditional\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    237\u001b[0m temp_tags[\u001b[39m'\u001b[39m\u001b[39mnegative_weights\u001b[39m\u001b[39m'\u001b[39m] \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39mwhere(temp_tags[\u001b[39m'\u001b[39m\u001b[39mlabel\u001b[39m\u001b[39m'\u001b[39m] \u001b[39m==\u001b[39m \u001b[39m0\u001b[39m , temp_tags[\u001b[39m'\u001b[39m\u001b[39mweights\u001b[39m\u001b[39m'\u001b[39m], \u001b[39m1\u001b[39m \u001b[39m-\u001b[39m temp_tags[\u001b[39m'\u001b[39m\u001b[39mweights\u001b[39m\u001b[39m'\u001b[39m])\n\u001b[1;32m    238\u001b[0m \u001b[39m# E(F(x) | Y^)\u001b[39;00m\n\u001b[1;32m    239\u001b[0m \u001b[39m# e_y_1 = sum(temp_tags['positive_weights'] * temp_tags[_PREDICTION])/ ( (len(temp_tags)) * self.p_y['label=1'])\u001b[39;00m\n\u001b[1;32m    240\u001b[0m \u001b[39m# e_y_0 = sum(temp_tags['negative_weights'] * temp_tags[_PREDICTION])/ ( (len(temp_tags)) * self.p_y['label=0'])\u001b[39;00m\n\u001b[1;32m    241\u001b[0m \u001b[39m# e_y_1 = sum(temp_tags['positive_weights'] * temp_tags[_PREDICTION])/ ( (len(temp_tags)) * self.prob_event['label=1'])\u001b[39;00m\n\u001b[1;32m    242\u001b[0m \u001b[39m# e_y_0 = sum(temp_tags['negative_weights'] * temp_tags[_PREDICTION])/ ( (len(temp_tags)) * self.prob_event['label=0'])\u001b[39;00m\n\u001b[0;32m--> 243\u001b[0m expect_event \u001b[39m=\u001b[39m pd\u001b[39m.\u001b[39mSeries([e_y_0, e_y_1], index \u001b[39m=\u001b[39m [\u001b[39m'\u001b[39m\u001b[39mlabel=0\u001b[39m\u001b[39m'\u001b[39m, \u001b[39m'\u001b[39m\u001b[39mlabel=1\u001b[39m\u001b[39m'\u001b[39m])\n\u001b[1;32m    244\u001b[0m expect_event\u001b[39m.\u001b[39mindex\u001b[39m.\u001b[39mnames \u001b[39m=\u001b[39m [\u001b[39m'\u001b[39m\u001b[39mevent\u001b[39m\u001b[39m'\u001b[39m]\n\u001b[1;32m    245\u001b[0m \u001b[39m# E(F(x) | S, Y )\u001b[39;00m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'e_y_0' is not defined"
     ]
    }
   ],
   "source": [
    "# Run Fair Reduction on every set \n",
    "base_path = 'results'\n",
    "for exp_name, data_obj in datasets.items():\n",
    "    # if exp_name in ['adult_bias_0.1', 'adult_bias_0.3', 'adult_flip_0.1']: continue\n",
    "    print(exp_name)\n",
    "    eval_labels =  data_obj.eval_labels()\n",
    "    meta = {\"name\": data_obj.name, \"noise\": data_obj.noise_type, \"level\": data_obj.noise_level}\n",
    "    res = []\n",
    "    \n",
    "    pred_dict = defaultdict(dict)\n",
    "    for fold, _data in data_obj.foldwise_data.items():\n",
    "        print(fold)\n",
    "        train_data, test_data = _data['train'], _data['test']\n",
    "        x_train, x_test = train_data.drop(data_obj.cols_to_drop, axis = 1,errors='ignore'), test_data.drop(data_obj.cols_to_drop, axis = 1,errors='ignore')\n",
    "        y_train, y_test = train_data[data_obj.label], test_data[data_obj.label]\n",
    "        sv_train, sv_test = train_data[data_obj.sensitive_attribute], test_data[data_obj.sensitive_attribute]\n",
    "        wts = {}\n",
    "        # if 'prob' in train_data.columns:\n",
    "        #     w_dict = {\n",
    "        #         \"weights\": train_data['prob'], \n",
    "        #         \"p_y\" : data_obj.fair_prob_map[fold]['p_y'],\n",
    "        #         \"p_y_s\": data_obj.fair_prob_map[fold]['p_y_s']\n",
    "        #     }\n",
    "        #     wts['fair'] = w_dict\n",
    "\n",
    "        if 'emp_prob' in train_data.columns:\n",
    "            \n",
    "            w_dict = {\n",
    "                \"weights\": train_data['emp_prob'], \n",
    "                \"p_y\" :  data_obj.emp_prob_map[fold]['train']['p_y'],\n",
    "                \"p_y_s\": data_obj.emp_prob_map[fold]['train']['p_y_s'],\n",
    "            }\n",
    "            wts['emp'] = w_dict\n",
    "        \n",
    "        for w_name, w in wts.items():\n",
    "            print(w_name)\n",
    "            # w_dict = {\n",
    "            #     \"weights\": w, \n",
    "            #     \"p_y\" : data_obj.p_y,\n",
    "            #     \"p_y_s\": data_obj.p_y_s\n",
    "            # }\n",
    "            # w_dict = {\n",
    "            #     \"weights\": w['weight'], \n",
    "            #     \"p_y\" : data_obj.fair_prob_map[fold]['p_y'],\n",
    "            #     \"p_y_s\": data_obj.fair_prob_map[fold]['p_y_s']\n",
    "            # }\n",
    "            _model = FairReduction().fit(x_train, y_train, sv_train, weights = w)\n",
    "            y_pred = _model.predict(x_test)\n",
    "            pred_path = os.path.join(base_path, \"fair_reduction\", data_obj.name, data_obj.exp_name, f\"FR_{w_name}\", fold)\n",
    "            os.makedirs(pred_path, exist_ok=True)\n",
    "            pd.DataFrame(y_pred).to_csv(os.path.join(pred_path, \"preds_2.csv\"))\n",
    "            pred_dict[w_name][fold] = y_pred\n",
    "            meta['fold'] = fold\n",
    "            meta['weights'] = w_name\n",
    "            for eval_type, _label in eval_labels.items():\n",
    "                if eval_type != 'ground': continue\n",
    "                meta['eval_type'] = eval_type\n",
    "                perf_dict = Metrics().performance_metrics(_label[fold], y_pred, 0.5, meta)\n",
    "                fair_dict = Metrics().fairness_metrics(_label[fold], y_pred, sv_test, threshold =  0.5, meta = perf_dict)\n",
    "                print(fair_dict)\n",
    "                res.append(fair_dict)\n",
    "    save_path = os.path.join(base_path, data_obj.name,data_obj.exp_name)\n",
    "    os.makedirs(save_path, exist_ok=True)\n",
    "    pd.DataFrame(res).to_csv(os.path.join(base_path, data_obj.name,data_obj.exp_name, \"fair_reduction_2.csv\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "thesis",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5 (main, Aug 24 2023, 15:09:45) [Clang 14.0.3 (clang-1403.0.22.14.1)]"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "f2adf8fc93cedafd578fe7dd39840acbd27ab9eaddec0fc7c286627d45824dbc"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

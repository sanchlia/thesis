{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import os\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd \n",
    "\n",
    "from bin.dataset import Dataset\n",
    "from bin.experiment import Experiment\n",
    "from bin.metrics import Metrics\n",
    "\n",
    "from collections import defaultdict\n",
    "\n",
    "from models.LR import Lr\n",
    "from models.reduction import Reduction\n",
    "from models.reweight import Reweight\n",
    "from models.fair_reduction import FairReduction\n",
    "\n",
    "from scipy.special import xlog1py\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import roc_auc_score, f1_score, precision_score, accuracy_score, recall_score\n",
    "from fairlearn.metrics import (\n",
    "    MetricFrame, plot_model_comparison,\n",
    "    selection_rate, demographic_parity_difference, demographic_parity_ratio,\n",
    "    false_positive_rate, false_negative_rate,\n",
    "    false_positive_rate_difference, false_negative_rate_difference,true_positive_rate, \n",
    "    equalized_odds_difference)\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = {\n",
    "    \"LR\": Lr, \n",
    "    \"Reduction\": Reduction,\n",
    "    \"Reweight\": Reweight\n",
    "}"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## UTILS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_config(path):\n",
    "    \"\"\"Reads the config file and returns a dictionary.\"\"\"\n",
    "    try:\n",
    "        with open(path) as f:\n",
    "            config = json.load(f)\n",
    "    except FileNotFoundError:\n",
    "        print(\"Config file not found.\")\n",
    "        config = None\n",
    "    return config\n",
    "\n",
    "def load_csv(path):\n",
    "    \"\"\"Loads the csv file and returns a dataframe.\"\"\"\n",
    "    try:\n",
    "        df = pd.read_csv(path)\n",
    "    except FileNotFoundError:\n",
    "        print(\"CSV file not found.\")\n",
    "        df = None\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## MAIN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "# exp_conf = \"configs/adult_noisy.json\"\n",
    "# exp_conf = \"configs/compas_noisy.json\"\n",
    "# exp_conf = \"configs/synthetic_20_noisy.json\"\n",
    "exp_conf = \"configs/income_noisy.json\"\n",
    "# exp_conf = \"configs/baseline_config.json\"\n",
    "\n",
    "EXP = read_config(exp_conf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['income_bias_0.1', 'income_bias_0.3', 'income_flip_0.1', 'income_flip_0.3', 'income_balanced_0.1', 'income_balanced_0.3'])"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "EXP.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "datasets = {}\n",
    "try:\n",
    "    for name, value in EXP.items():\n",
    "        # if name in ['adult_bias_0.1','adult_bias_0.3']: continue\n",
    "        # if name in ['COMPAS_balanced_0.1']: continue\n",
    "        if not name in ['income_balanced_0.1', 'income_balanced_0.3']: continue\n",
    "        # if name  not in ['synthetic_20_balanced_0.1', 'synthetic_20_balanced_0.3']: continue\n",
    "        datasets[name] = Dataset(value)\n",
    "        # datasets[name].calculate_probabilities()\n",
    "\n",
    "except Exception as e:\n",
    "    print(e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'income_balanced_0.1': <bin.dataset.Dataset at 0x1656a3950>,\n",
       " 'income_balanced_0.3': <bin.dataset.Dataset at 0x1655cd4d0>}"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "income_balanced_0.1\n",
      "x1\n",
      "fair_clean\n",
      "emp_clean\n",
      "noisy\n",
      "ground\n",
      "fair_clean\n",
      "emp_clean\n",
      "noisy\n",
      "ground\n",
      "fair_clean\n",
      "emp_clean\n",
      "noisy\n",
      "ground\n",
      "x2\n",
      "fair_clean\n",
      "emp_clean\n",
      "noisy\n",
      "ground\n",
      "fair_clean\n",
      "emp_clean\n",
      "noisy\n",
      "ground\n",
      "fair_clean\n",
      "emp_clean\n",
      "noisy\n",
      "ground\n",
      "x3\n",
      "fair_clean\n",
      "emp_clean\n",
      "noisy\n",
      "ground\n",
      "fair_clean\n",
      "emp_clean\n",
      "noisy\n",
      "ground\n",
      "fair_clean\n",
      "emp_clean\n",
      "noisy\n",
      "ground\n",
      "x4\n",
      "fair_clean\n",
      "emp_clean\n",
      "noisy\n",
      "ground\n",
      "fair_clean\n",
      "emp_clean\n",
      "noisy\n",
      "ground\n",
      "fair_clean\n",
      "emp_clean\n",
      "noisy\n",
      "ground\n",
      "x5\n",
      "fair_clean\n",
      "emp_clean\n",
      "noisy\n",
      "ground\n",
      "fair_clean\n",
      "emp_clean\n",
      "noisy\n",
      "ground\n",
      "fair_clean\n",
      "emp_clean\n",
      "noisy\n",
      "ground\n",
      "x6\n",
      "fair_clean\n",
      "emp_clean\n",
      "noisy\n",
      "ground\n",
      "fair_clean\n",
      "emp_clean\n",
      "noisy\n",
      "ground\n",
      "fair_clean\n",
      "emp_clean\n",
      "noisy\n",
      "ground\n",
      "x7\n",
      "fair_clean\n",
      "emp_clean\n",
      "noisy\n",
      "ground\n",
      "fair_clean\n",
      "emp_clean\n",
      "noisy\n",
      "ground\n",
      "fair_clean\n",
      "emp_clean\n",
      "noisy\n",
      "ground\n",
      "x8\n",
      "fair_clean\n",
      "emp_clean\n",
      "noisy\n",
      "ground\n",
      "fair_clean\n",
      "emp_clean\n",
      "noisy\n",
      "ground\n",
      "fair_clean\n",
      "emp_clean\n",
      "noisy\n",
      "ground\n",
      "x9\n",
      "fair_clean\n",
      "emp_clean\n",
      "noisy\n",
      "ground\n",
      "fair_clean\n",
      "emp_clean\n",
      "noisy\n",
      "ground\n",
      "fair_clean\n",
      "emp_clean\n",
      "noisy\n",
      "ground\n",
      "x10\n",
      "fair_clean\n",
      "emp_clean\n",
      "noisy\n",
      "ground\n",
      "fair_clean\n",
      "emp_clean\n",
      "noisy\n",
      "ground\n",
      "fair_clean\n",
      "emp_clean\n",
      "noisy\n",
      "ground\n",
      "income_balanced_0.3\n",
      "x1\n",
      "fair_clean\n",
      "emp_clean\n",
      "noisy\n",
      "ground\n",
      "fair_clean\n",
      "emp_clean\n",
      "noisy\n",
      "ground\n",
      "fair_clean\n",
      "emp_clean\n",
      "noisy\n",
      "ground\n",
      "x2\n",
      "fair_clean\n",
      "emp_clean\n",
      "noisy\n",
      "ground\n",
      "fair_clean\n",
      "emp_clean\n",
      "noisy\n",
      "ground\n",
      "fair_clean\n",
      "emp_clean\n",
      "noisy\n",
      "ground\n",
      "x3\n",
      "fair_clean\n",
      "emp_clean\n",
      "noisy\n",
      "ground\n",
      "fair_clean\n",
      "emp_clean\n",
      "noisy\n",
      "ground\n",
      "fair_clean\n",
      "emp_clean\n",
      "noisy\n",
      "ground\n",
      "x4\n",
      "fair_clean\n",
      "emp_clean\n",
      "noisy\n",
      "ground\n",
      "fair_clean\n",
      "emp_clean\n",
      "noisy\n",
      "ground\n",
      "fair_clean\n",
      "emp_clean\n",
      "noisy\n",
      "ground\n",
      "x5\n",
      "fair_clean\n",
      "emp_clean\n",
      "noisy\n",
      "ground\n",
      "fair_clean\n",
      "emp_clean\n",
      "noisy\n",
      "ground\n",
      "fair_clean\n",
      "emp_clean\n",
      "noisy\n",
      "ground\n",
      "x6\n",
      "fair_clean\n",
      "emp_clean\n",
      "noisy\n",
      "ground\n",
      "fair_clean\n",
      "emp_clean\n",
      "noisy\n",
      "ground\n",
      "fair_clean\n",
      "emp_clean\n",
      "noisy\n",
      "ground\n",
      "x7\n",
      "fair_clean\n",
      "emp_clean\n",
      "noisy\n",
      "ground\n",
      "fair_clean\n",
      "emp_clean\n",
      "noisy\n",
      "ground\n",
      "fair_clean\n",
      "emp_clean\n",
      "noisy\n",
      "ground\n",
      "x8\n",
      "fair_clean\n",
      "emp_clean\n",
      "noisy\n",
      "ground\n",
      "fair_clean\n",
      "emp_clean\n",
      "noisy\n",
      "ground\n",
      "fair_clean\n",
      "emp_clean\n",
      "noisy\n",
      "ground\n",
      "x9\n",
      "fair_clean\n",
      "emp_clean\n",
      "noisy\n",
      "ground\n",
      "fair_clean\n",
      "emp_clean\n",
      "noisy\n",
      "ground\n",
      "fair_clean\n",
      "emp_clean\n",
      "noisy\n",
      "ground\n",
      "x10\n",
      "fair_clean\n",
      "emp_clean\n",
      "noisy\n",
      "ground\n",
      "fair_clean\n",
      "emp_clean\n",
      "noisy\n",
      "ground\n",
      "fair_clean\n",
      "emp_clean\n",
      "noisy\n",
      "ground\n"
     ]
    }
   ],
   "source": [
    "# Run audit on every set \n",
    "base_path = \"results\"\n",
    "for exp_name, data_obj in datasets.items():\n",
    "    print(exp_name)\n",
    "    # if exp_name not in ['adult_bias_0.1','adult_bias_0.3']: continue\n",
    "    eval_labels =  data_obj.eval_labels()\n",
    "    meta = {\"name\": data_obj.name, \"noise\": data_obj.noise_type, \"level\": data_obj.noise_level}\n",
    "    res = []\n",
    "    pred_dict = defaultdict(dict)\n",
    "    for fold, _data in data_obj.foldwise_data.items():\n",
    "        print(fold)\n",
    "        train_data, test_data = _data['train'], _data['test']\n",
    "        x_train, x_test = train_data.drop(data_obj.cols_to_drop, axis = 1, errors='ignore'), test_data.drop(data_obj.cols_to_drop, axis = 1, errors='ignore')\n",
    "        y_train, y_test = train_data[data_obj.label], test_data[data_obj.label]\n",
    "        sv_train, sv_test = train_data[data_obj.sensitive_attribute], test_data[data_obj.sensitive_attribute]\n",
    "        \n",
    "        \n",
    "        for m_name, clf in model.items():\n",
    "            _model = clf().fit(x_train, y_train, sv_train)\n",
    "            y_pred = _model.predict(x_test)\n",
    "            pred_path = os.path.join(base_path, \"audit\", data_obj.name, data_obj.exp_name, m_name, fold)\n",
    "            os.makedirs(pred_path, exist_ok=True)\n",
    "            pd.DataFrame(y_pred).to_csv(os.path.join(pred_path, \"preds.csv\"))\n",
    "            meta['fold'] = fold\n",
    "            meta['model'] = m_name\n",
    "\n",
    "            \n",
    "            for eval_type, _label in eval_labels.items():\n",
    "                print(eval_type)\n",
    "                meta['eval_type'] = eval_type\n",
    "                perf_dict = Metrics().performance_metrics(_label[fold], y_pred, 0.5, meta)\n",
    "                fair_dict = Metrics().fairness_metrics(_label[fold], y_pred, sv_test, threshold =  0.5, meta = perf_dict)\n",
    "                # expected_dict = Metrics.estimated_metrics()\n",
    "                # print(fair_dict)\n",
    "                res.append(fair_dict)\n",
    "    save_path = os.path.join(base_path    \n",
    "                             , data_obj.name,data_obj.exp_name)\n",
    "    os.makedirs(save_path, exist_ok=True)\n",
    "    pd.DataFrame(res).to_csv(os.path.join(save_path, \"audit.csv\"))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "b0fa6594d8f4cbf19f97940f81e996739fb7646882a419484c72d19e05852a7e"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

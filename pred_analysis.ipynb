{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "from bin.dataset import Dataset\n",
    "from collections import defaultdict\n",
    "from bin.metrics import Metrics\n",
    "\n",
    "\n",
    "import json\n",
    "import os\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = {\n",
    "    \"LR\": None, \n",
    "    \"Reduction\": None,\n",
    "    \"Reweight\": None\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_config(path):\n",
    "    \"\"\"Reads the config file and returns a dictionary.\"\"\"\n",
    "    try:\n",
    "        with open(path) as f:\n",
    "            config = json.load(f)\n",
    "    except FileNotFoundError:\n",
    "        print(\"Config file not found.\")\n",
    "        config = None\n",
    "    return config\n",
    "\n",
    "def load_csv(path):\n",
    "    \"\"\"Loads the csv file and returns a dataframe.\"\"\"\n",
    "    try:\n",
    "        df = pd.read_csv(path)\n",
    "    except FileNotFoundError:\n",
    "        print(\"CSV file not found.\")\n",
    "        df = None\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# exp_conf = \"configs/adult_noisy.json\"\n",
    "# exp_conf = \"configs/compas_noisy.json\"\n",
    "# exp_conf = \"configs/synthetic_20_noisy.json\"\n",
    "exp_conf = \"configs/income_noisy.json\"\n",
    "# exp_conf = \"configs/baseline_config.json\"\n",
    "\n",
    "EXP = read_config(exp_conf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "datasets = {}\n",
    "try:\n",
    "    for name, value in EXP.items():\n",
    "        # if name in ['COMPAS_bias_0.1', 'COMPAS_balanced_0.1']: continue\n",
    "        # if name in ['income_balanced_0.1', 'income_balanced_0.3']: continue\n",
    "        # if not name in ['synthetic_20_balanced_0.1']: continue\n",
    "        datasets[name] = Dataset(value)\n",
    "        datasets[name].calculate_probabilities(\"fair\")\n",
    "        datasets[name].calculate_probabilities(\"emp\")\n",
    "        \n",
    "\n",
    "except Exception as e:\n",
    "    print(e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'income_bias_0.1': <bin.dataset.Dataset at 0x2a2314b10>,\n",
       " 'income_bias_0.3': <bin.dataset.Dataset at 0x2a2160b50>,\n",
       " 'income_flip_0.1': <bin.dataset.Dataset at 0x13d4968d0>,\n",
       " 'income_flip_0.3': <bin.dataset.Dataset at 0x2a251a490>,\n",
       " 'income_balanced_0.1': <bin.dataset.Dataset at 0x2a250da10>,\n",
       " 'income_balanced_0.3': <bin.dataset.Dataset at 0x2a22fe150>}"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "income_bias_0.1\n",
      "x1\n",
      "fair\n"
     ]
    },
    {
     "ename": "KeyError",
     "evalue": "0",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "File \u001b[0;32m~/Fair_ML/Projects/thesis/FL08/lib/python3.11/site-packages/pandas/core/indexes/base.py:3790\u001b[0m, in \u001b[0;36mIndex.get_loc\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   3789\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m-> 3790\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_engine\u001b[39m.\u001b[39;49mget_loc(casted_key)\n\u001b[1;32m   3791\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mKeyError\u001b[39;00m \u001b[39mas\u001b[39;00m err:\n",
      "File \u001b[0;32mindex.pyx:152\u001b[0m, in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32mindex.pyx:181\u001b[0m, in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32mpandas/_libs/hashtable_class_helper.pxi:7080\u001b[0m, in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32mpandas/_libs/hashtable_class_helper.pxi:7088\u001b[0m, in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mKeyError\u001b[0m: 0",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[26], line 44\u001b[0m\n\u001b[1;32m     41\u001b[0m meta[\u001b[39m'\u001b[39m\u001b[39meval_type\u001b[39m\u001b[39m'\u001b[39m] \u001b[39m=\u001b[39m w_name\n\u001b[1;32m     42\u001b[0m \u001b[39m# perf_dict = Metrics().performance_metrics(_label[fold], y_pred, 0.5, meta)\u001b[39;00m\n\u001b[1;32m     43\u001b[0m \u001b[39m# fair_dict = Metrics().fairness_metrics(_label[fold], y_pred, sv_test, threshold =  0.5, meta = perf_dict)\u001b[39;00m\n\u001b[0;32m---> 44\u001b[0m expected_dict \u001b[39m=\u001b[39m Metrics()\u001b[39m.\u001b[39;49mestimated_metrics(eval_labels[\u001b[39m'\u001b[39;49m\u001b[39mground\u001b[39;49m\u001b[39m'\u001b[39;49m][fold], y_pred, sv_test, w,meta \u001b[39m=\u001b[39;49m meta)\n\u001b[1;32m     45\u001b[0m \u001b[39mprint\u001b[39m(expected_dict)\n\u001b[1;32m     46\u001b[0m res\u001b[39m.\u001b[39mappend(expected_dict)\n",
      "File \u001b[0;32m~/Fair_ML/Projects/thesis/bin/metrics.py:80\u001b[0m, in \u001b[0;36mMetrics.estimated_metrics\u001b[0;34m(self, y_true, y_pred, sv, weights_dict, meta)\u001b[0m\n\u001b[1;32m     78\u001b[0m res \u001b[39m=\u001b[39m {}\n\u001b[1;32m     79\u001b[0m res[\u001b[39m'\u001b[39m\u001b[39mest_acc\u001b[39m\u001b[39m'\u001b[39m] \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mexpected_accuracy(y_true, y_pred, weights_dict[\u001b[39m'\u001b[39m\u001b[39mweights\u001b[39m\u001b[39m'\u001b[39m])\n\u001b[0;32m---> 80\u001b[0m res[\u001b[39m'\u001b[39m\u001b[39mest_eop\u001b[39m\u001b[39m'\u001b[39m] \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mweq(sv, y_true, y_pred, weights_dict[\u001b[39m'\u001b[39;49m\u001b[39mweights\u001b[39;49m\u001b[39m'\u001b[39;49m], weights_dict[\u001b[39m'\u001b[39;49m\u001b[39mp_y_s\u001b[39;49m\u001b[39m'\u001b[39;49m])\n\u001b[1;32m     81\u001b[0m res\u001b[39m.\u001b[39mupdate(meta)\n\u001b[1;32m     82\u001b[0m \u001b[39mreturn\u001b[39;00m res\n",
      "File \u001b[0;32m~/Fair_ML/Projects/thesis/bin/metrics.py:119\u001b[0m, in \u001b[0;36mMetrics.weq\u001b[0;34m(self, sv, y_f, y_hat, fair_weights, p_y)\u001b[0m\n\u001b[1;32m    116\u001b[0m group_event_index \u001b[39m=\u001b[39m pd\u001b[39m.\u001b[39mMultiIndex\u001b[39m.\u001b[39mfrom_tuples(group_event_tuples, names \u001b[39m=\u001b[39m [\u001b[39m'\u001b[39m\u001b[39mevent\u001b[39m\u001b[39m'\u001b[39m, \u001b[39m'\u001b[39m\u001b[39mgroup_id\u001b[39m\u001b[39m'\u001b[39m])\n\u001b[1;32m    118\u001b[0m weighted_si \u001b[39m=\u001b[39m (df[df[\u001b[39m'\u001b[39m\u001b[39my_hat\u001b[39m\u001b[39m'\u001b[39m] \u001b[39m==\u001b[39m \u001b[39m1\u001b[39m])\u001b[39m.\u001b[39mgroupby([\u001b[39m\"\u001b[39m\u001b[39mevent\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39m'\u001b[39m\u001b[39mgroup_id\u001b[39m\u001b[39m'\u001b[39m])\u001b[39m.\u001b[39msum()[\u001b[39m'\u001b[39m\u001b[39mw\u001b[39m\u001b[39m'\u001b[39m]\n\u001b[0;32m--> 119\u001b[0m weighted_si \u001b[39m=\u001b[39m pd\u001b[39m.\u001b[39mSeries([weighted_si\u001b[39m.\u001b[39;49mloc[\u001b[39m0\u001b[39;49m][\u001b[39m0\u001b[39m], weighted_si\u001b[39m.\u001b[39mloc[\u001b[39m0\u001b[39m][\u001b[39m1\u001b[39m], weighted_si\u001b[39m.\u001b[39mloc[\u001b[39m1\u001b[39m][\u001b[39m0\u001b[39m],  weighted_si\u001b[39m.\u001b[39mloc[\u001b[39m1\u001b[39m][\u001b[39m1\u001b[39m]], index \u001b[39m=\u001b[39m group_event_index)\n\u001b[1;32m    120\u001b[0m counts  \u001b[39m=\u001b[39m df\u001b[39m.\u001b[39mgroupby([\u001b[39m\"\u001b[39m\u001b[39mgroup_id\u001b[39m\u001b[39m\"\u001b[39m])\u001b[39m.\u001b[39msize()\n\u001b[1;32m    121\u001b[0m \u001b[39m# print(f'{counts=}')\u001b[39;00m\n",
      "File \u001b[0;32m~/Fair_ML/Projects/thesis/FL08/lib/python3.11/site-packages/pandas/core/indexing.py:1153\u001b[0m, in \u001b[0;36m_LocationIndexer.__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   1150\u001b[0m axis \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39maxis \u001b[39mor\u001b[39;00m \u001b[39m0\u001b[39m\n\u001b[1;32m   1152\u001b[0m maybe_callable \u001b[39m=\u001b[39m com\u001b[39m.\u001b[39mapply_if_callable(key, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mobj)\n\u001b[0;32m-> 1153\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_getitem_axis(maybe_callable, axis\u001b[39m=\u001b[39;49maxis)\n",
      "File \u001b[0;32m~/Fair_ML/Projects/thesis/FL08/lib/python3.11/site-packages/pandas/core/indexing.py:1393\u001b[0m, in \u001b[0;36m_LocIndexer._getitem_axis\u001b[0;34m(self, key, axis)\u001b[0m\n\u001b[1;32m   1391\u001b[0m \u001b[39m# fall thru to straight lookup\u001b[39;00m\n\u001b[1;32m   1392\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_validate_key(key, axis)\n\u001b[0;32m-> 1393\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_get_label(key, axis\u001b[39m=\u001b[39;49maxis)\n",
      "File \u001b[0;32m~/Fair_ML/Projects/thesis/FL08/lib/python3.11/site-packages/pandas/core/indexing.py:1343\u001b[0m, in \u001b[0;36m_LocIndexer._get_label\u001b[0;34m(self, label, axis)\u001b[0m\n\u001b[1;32m   1341\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_get_label\u001b[39m(\u001b[39mself\u001b[39m, label, axis: AxisInt):\n\u001b[1;32m   1342\u001b[0m     \u001b[39m# GH#5567 this will fail if the label is not present in the axis.\u001b[39;00m\n\u001b[0;32m-> 1343\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mobj\u001b[39m.\u001b[39;49mxs(label, axis\u001b[39m=\u001b[39;49maxis)\n",
      "File \u001b[0;32m~/Fair_ML/Projects/thesis/FL08/lib/python3.11/site-packages/pandas/core/generic.py:4228\u001b[0m, in \u001b[0;36mNDFrame.xs\u001b[0;34m(self, key, axis, level, drop_level)\u001b[0m\n\u001b[1;32m   4225\u001b[0m     index \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mindex\n\u001b[1;32m   4227\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39misinstance\u001b[39m(index, MultiIndex):\n\u001b[0;32m-> 4228\u001b[0m     loc, new_index \u001b[39m=\u001b[39m index\u001b[39m.\u001b[39;49m_get_loc_level(key, level\u001b[39m=\u001b[39;49m\u001b[39m0\u001b[39;49m)\n\u001b[1;32m   4229\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m drop_level:\n\u001b[1;32m   4230\u001b[0m         \u001b[39mif\u001b[39;00m lib\u001b[39m.\u001b[39mis_integer(loc):\n\u001b[1;32m   4231\u001b[0m             \u001b[39m# Slice index must be an integer or None\u001b[39;00m\n",
      "File \u001b[0;32m~/Fair_ML/Projects/thesis/FL08/lib/python3.11/site-packages/pandas/core/indexes/multi.py:3175\u001b[0m, in \u001b[0;36mMultiIndex._get_loc_level\u001b[0;34m(self, key, level)\u001b[0m\n\u001b[1;32m   3173\u001b[0m         \u001b[39mreturn\u001b[39;00m indexer, maybe_mi_droplevels(indexer, ilevels)\n\u001b[1;32m   3174\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m-> 3175\u001b[0m     indexer \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_get_level_indexer(key, level\u001b[39m=\u001b[39;49mlevel)\n\u001b[1;32m   3176\u001b[0m     \u001b[39mif\u001b[39;00m (\n\u001b[1;32m   3177\u001b[0m         \u001b[39misinstance\u001b[39m(key, \u001b[39mstr\u001b[39m)\n\u001b[1;32m   3178\u001b[0m         \u001b[39mand\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mlevels[level]\u001b[39m.\u001b[39m_supports_partial_string_indexing\n\u001b[1;32m   3179\u001b[0m     ):\n\u001b[1;32m   3180\u001b[0m         \u001b[39m# check to see if we did an exact lookup vs sliced\u001b[39;00m\n\u001b[1;32m   3181\u001b[0m         check \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mlevels[level]\u001b[39m.\u001b[39mget_loc(key)\n",
      "File \u001b[0;32m~/Fair_ML/Projects/thesis/FL08/lib/python3.11/site-packages/pandas/core/indexes/multi.py:3276\u001b[0m, in \u001b[0;36mMultiIndex._get_level_indexer\u001b[0;34m(self, key, level, indexer)\u001b[0m\n\u001b[1;32m   3273\u001b[0m         \u001b[39mreturn\u001b[39;00m \u001b[39mslice\u001b[39m(i, j, step)\n\u001b[1;32m   3275\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m-> 3276\u001b[0m     idx \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_get_loc_single_level_index(level_index, key)\n\u001b[1;32m   3278\u001b[0m     \u001b[39mif\u001b[39;00m level \u001b[39m>\u001b[39m \u001b[39m0\u001b[39m \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_lexsort_depth \u001b[39m==\u001b[39m \u001b[39m0\u001b[39m:\n\u001b[1;32m   3279\u001b[0m         \u001b[39m# Desired level is not sorted\u001b[39;00m\n\u001b[1;32m   3280\u001b[0m         \u001b[39mif\u001b[39;00m \u001b[39misinstance\u001b[39m(idx, \u001b[39mslice\u001b[39m):\n\u001b[1;32m   3281\u001b[0m             \u001b[39m# test_get_loc_partial_timestamp_multiindex\u001b[39;00m\n",
      "File \u001b[0;32m~/Fair_ML/Projects/thesis/FL08/lib/python3.11/site-packages/pandas/core/indexes/multi.py:2865\u001b[0m, in \u001b[0;36mMultiIndex._get_loc_single_level_index\u001b[0;34m(self, level_index, key)\u001b[0m\n\u001b[1;32m   2863\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39m-\u001b[39m\u001b[39m1\u001b[39m\n\u001b[1;32m   2864\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m-> 2865\u001b[0m     \u001b[39mreturn\u001b[39;00m level_index\u001b[39m.\u001b[39;49mget_loc(key)\n",
      "File \u001b[0;32m~/Fair_ML/Projects/thesis/FL08/lib/python3.11/site-packages/pandas/core/indexes/base.py:3797\u001b[0m, in \u001b[0;36mIndex.get_loc\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   3792\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39misinstance\u001b[39m(casted_key, \u001b[39mslice\u001b[39m) \u001b[39mor\u001b[39;00m (\n\u001b[1;32m   3793\u001b[0m         \u001b[39misinstance\u001b[39m(casted_key, abc\u001b[39m.\u001b[39mIterable)\n\u001b[1;32m   3794\u001b[0m         \u001b[39mand\u001b[39;00m \u001b[39many\u001b[39m(\u001b[39misinstance\u001b[39m(x, \u001b[39mslice\u001b[39m) \u001b[39mfor\u001b[39;00m x \u001b[39min\u001b[39;00m casted_key)\n\u001b[1;32m   3795\u001b[0m     ):\n\u001b[1;32m   3796\u001b[0m         \u001b[39mraise\u001b[39;00m InvalidIndexError(key)\n\u001b[0;32m-> 3797\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mKeyError\u001b[39;00m(key) \u001b[39mfrom\u001b[39;00m \u001b[39merr\u001b[39;00m\n\u001b[1;32m   3798\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mTypeError\u001b[39;00m:\n\u001b[1;32m   3799\u001b[0m     \u001b[39m# If we have a listlike key, _check_indexing_error will raise\u001b[39;00m\n\u001b[1;32m   3800\u001b[0m     \u001b[39m#  InvalidIndexError. Otherwise we fall through and re-raise\u001b[39;00m\n\u001b[1;32m   3801\u001b[0m     \u001b[39m#  the TypeError.\u001b[39;00m\n\u001b[1;32m   3802\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_check_indexing_error(key)\n",
      "\u001b[0;31mKeyError\u001b[0m: 0"
     ]
    }
   ],
   "source": [
    "# Run audit on every set \n",
    "base_path = \"results\"\n",
    "for exp_name, data_obj in datasets.items():\n",
    "    # if exp_name != 'adult_flip_0.1': continue\n",
    "    print(exp_name)\n",
    "    eval_labels =  data_obj.eval_labels()\n",
    "    meta = {\"name\": data_obj.name, \"noise\": data_obj.noise_type, \"level\": data_obj.noise_level}\n",
    "    res = []\n",
    "    pred_dict = defaultdict(dict)\n",
    "    wts = {}\n",
    "    for fold, _data in data_obj.foldwise_data.items():\n",
    "        # if fold != 'x2': continue\n",
    "        print(fold)    \n",
    "        sv_test =  _data['test'][data_obj.sensitive_attribute]\n",
    "        if 'prob' in _data['train'].columns:\n",
    "            w_dict = {\n",
    "                \"weights\": _data['test']['prob'], \n",
    "                \"p_y\" : data_obj.fair_prob_map[fold]['p_y'],\n",
    "                \"p_y_s\": data_obj.fair_prob_map[fold]['p_y_s']\n",
    "            }\n",
    "            wts['fair'] = w_dict\n",
    "\n",
    "        if 'emp_prob' in _data['train'].columns:\n",
    "            \n",
    "            w_dict = {\n",
    "                \"weights\": _data['test']['emp_prob'], \n",
    "                \"p_y\" :  data_obj.emp_prob_map[fold]['test']['p_y'],\n",
    "                \"p_y_s\": data_obj.emp_prob_map[fold]['test']['p_y_s'],\n",
    "            }\n",
    "            wts['emp'] = w_dict\n",
    "        for m_name in model.keys():\n",
    "            pred_path = os.path.join(base_path, \"audit\", data_obj.name, data_obj.exp_name, m_name, fold)\n",
    "            pred = pd.read_csv(os.path.join(pred_path, 'preds.csv'))\n",
    "            y_pred = pred['0']\n",
    "            meta['fold'] = fold\n",
    "            meta['model'] = m_name\n",
    "\n",
    "            \n",
    "            for w_name, w in wts.items():\n",
    "                print(w_name)\n",
    "                meta['eval_type'] = w_name\n",
    "                # perf_dict = Metrics().performance_metrics(_label[fold], y_pred, 0.5, meta)\n",
    "                # fair_dict = Metrics().fairness_metrics(_label[fold], y_pred, sv_test, threshold =  0.5, meta = perf_dict)\n",
    "                expected_dict = Metrics().estimated_metrics(eval_labels['ground'][fold], y_pred, sv_test, w,meta = meta)\n",
    "                print(expected_dict)\n",
    "                res.append(expected_dict)\n",
    "    save_path = os.path.join(base_path    \n",
    "                             , data_obj.name,data_obj.exp_name)\n",
    "    os.makedirs(save_path, exist_ok=True)\n",
    "    pd.DataFrame(res).to_csv(os.path.join(save_path, \"expected_audit.csv\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "synthetic_20_balanced_0.1\n",
      "x1\n"
     ]
    },
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'results/cleanup/synthetic_20/synthetic_20_balanced_0.1/LR/x1/fair/preds.csv'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[38], line 27\u001b[0m\n\u001b[1;32m     25\u001b[0m \u001b[39mfor\u001b[39;00m m_name, clf \u001b[39min\u001b[39;00m model\u001b[39m.\u001b[39mitems():\n\u001b[1;32m     26\u001b[0m     pred_path \u001b[39m=\u001b[39m os\u001b[39m.\u001b[39mpath\u001b[39m.\u001b[39mjoin(base_path, \u001b[39m\"\u001b[39m\u001b[39mcleanup\u001b[39m\u001b[39m\"\u001b[39m, data_obj\u001b[39m.\u001b[39mname, data_obj\u001b[39m.\u001b[39mexp_name, m_name, fold, label_type )\n\u001b[0;32m---> 27\u001b[0m     pred \u001b[39m=\u001b[39m pd\u001b[39m.\u001b[39;49mread_csv(os\u001b[39m.\u001b[39;49mpath\u001b[39m.\u001b[39;49mjoin(pred_path, \u001b[39m'\u001b[39;49m\u001b[39mpreds.csv\u001b[39;49m\u001b[39m'\u001b[39;49m))\n\u001b[1;32m     28\u001b[0m     y_pred \u001b[39m=\u001b[39m pred[\u001b[39m'\u001b[39m\u001b[39m0\u001b[39m\u001b[39m'\u001b[39m]\n\u001b[1;32m     30\u001b[0m     meta[\u001b[39m'\u001b[39m\u001b[39mfold\u001b[39m\u001b[39m'\u001b[39m] \u001b[39m=\u001b[39m fold\n",
      "File \u001b[0;32m~/Fair_ML/Projects/thesis/thesis/lib/python3.11/site-packages/pandas/io/parsers/readers.py:1024\u001b[0m, in \u001b[0;36mread_csv\u001b[0;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, date_format, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, encoding_errors, dialect, on_bad_lines, delim_whitespace, low_memory, memory_map, float_precision, storage_options, dtype_backend)\u001b[0m\n\u001b[1;32m   1011\u001b[0m kwds_defaults \u001b[39m=\u001b[39m _refine_defaults_read(\n\u001b[1;32m   1012\u001b[0m     dialect,\n\u001b[1;32m   1013\u001b[0m     delimiter,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1020\u001b[0m     dtype_backend\u001b[39m=\u001b[39mdtype_backend,\n\u001b[1;32m   1021\u001b[0m )\n\u001b[1;32m   1022\u001b[0m kwds\u001b[39m.\u001b[39mupdate(kwds_defaults)\n\u001b[0;32m-> 1024\u001b[0m \u001b[39mreturn\u001b[39;00m _read(filepath_or_buffer, kwds)\n",
      "File \u001b[0;32m~/Fair_ML/Projects/thesis/thesis/lib/python3.11/site-packages/pandas/io/parsers/readers.py:618\u001b[0m, in \u001b[0;36m_read\u001b[0;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[1;32m    615\u001b[0m _validate_names(kwds\u001b[39m.\u001b[39mget(\u001b[39m\"\u001b[39m\u001b[39mnames\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39mNone\u001b[39;00m))\n\u001b[1;32m    617\u001b[0m \u001b[39m# Create the parser.\u001b[39;00m\n\u001b[0;32m--> 618\u001b[0m parser \u001b[39m=\u001b[39m TextFileReader(filepath_or_buffer, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwds)\n\u001b[1;32m    620\u001b[0m \u001b[39mif\u001b[39;00m chunksize \u001b[39mor\u001b[39;00m iterator:\n\u001b[1;32m    621\u001b[0m     \u001b[39mreturn\u001b[39;00m parser\n",
      "File \u001b[0;32m~/Fair_ML/Projects/thesis/thesis/lib/python3.11/site-packages/pandas/io/parsers/readers.py:1618\u001b[0m, in \u001b[0;36mTextFileReader.__init__\u001b[0;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[1;32m   1615\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39moptions[\u001b[39m\"\u001b[39m\u001b[39mhas_index_names\u001b[39m\u001b[39m\"\u001b[39m] \u001b[39m=\u001b[39m kwds[\u001b[39m\"\u001b[39m\u001b[39mhas_index_names\u001b[39m\u001b[39m\"\u001b[39m]\n\u001b[1;32m   1617\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mhandles: IOHandles \u001b[39m|\u001b[39m \u001b[39mNone\u001b[39;00m \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n\u001b[0;32m-> 1618\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_engine \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_make_engine(f, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mengine)\n",
      "File \u001b[0;32m~/Fair_ML/Projects/thesis/thesis/lib/python3.11/site-packages/pandas/io/parsers/readers.py:1878\u001b[0m, in \u001b[0;36mTextFileReader._make_engine\u001b[0;34m(self, f, engine)\u001b[0m\n\u001b[1;32m   1876\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39m\"\u001b[39m\u001b[39mb\u001b[39m\u001b[39m\"\u001b[39m \u001b[39mnot\u001b[39;00m \u001b[39min\u001b[39;00m mode:\n\u001b[1;32m   1877\u001b[0m         mode \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mb\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m-> 1878\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mhandles \u001b[39m=\u001b[39m get_handle(\n\u001b[1;32m   1879\u001b[0m     f,\n\u001b[1;32m   1880\u001b[0m     mode,\n\u001b[1;32m   1881\u001b[0m     encoding\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49moptions\u001b[39m.\u001b[39;49mget(\u001b[39m\"\u001b[39;49m\u001b[39mencoding\u001b[39;49m\u001b[39m\"\u001b[39;49m, \u001b[39mNone\u001b[39;49;00m),\n\u001b[1;32m   1882\u001b[0m     compression\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49moptions\u001b[39m.\u001b[39;49mget(\u001b[39m\"\u001b[39;49m\u001b[39mcompression\u001b[39;49m\u001b[39m\"\u001b[39;49m, \u001b[39mNone\u001b[39;49;00m),\n\u001b[1;32m   1883\u001b[0m     memory_map\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49moptions\u001b[39m.\u001b[39;49mget(\u001b[39m\"\u001b[39;49m\u001b[39mmemory_map\u001b[39;49m\u001b[39m\"\u001b[39;49m, \u001b[39mFalse\u001b[39;49;00m),\n\u001b[1;32m   1884\u001b[0m     is_text\u001b[39m=\u001b[39;49mis_text,\n\u001b[1;32m   1885\u001b[0m     errors\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49moptions\u001b[39m.\u001b[39;49mget(\u001b[39m\"\u001b[39;49m\u001b[39mencoding_errors\u001b[39;49m\u001b[39m\"\u001b[39;49m, \u001b[39m\"\u001b[39;49m\u001b[39mstrict\u001b[39;49m\u001b[39m\"\u001b[39;49m),\n\u001b[1;32m   1886\u001b[0m     storage_options\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49moptions\u001b[39m.\u001b[39;49mget(\u001b[39m\"\u001b[39;49m\u001b[39mstorage_options\u001b[39;49m\u001b[39m\"\u001b[39;49m, \u001b[39mNone\u001b[39;49;00m),\n\u001b[1;32m   1887\u001b[0m )\n\u001b[1;32m   1888\u001b[0m \u001b[39massert\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mhandles \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m\n\u001b[1;32m   1889\u001b[0m f \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mhandles\u001b[39m.\u001b[39mhandle\n",
      "File \u001b[0;32m~/Fair_ML/Projects/thesis/thesis/lib/python3.11/site-packages/pandas/io/common.py:873\u001b[0m, in \u001b[0;36mget_handle\u001b[0;34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\u001b[0m\n\u001b[1;32m    868\u001b[0m \u001b[39melif\u001b[39;00m \u001b[39misinstance\u001b[39m(handle, \u001b[39mstr\u001b[39m):\n\u001b[1;32m    869\u001b[0m     \u001b[39m# Check whether the filename is to be opened in binary mode.\u001b[39;00m\n\u001b[1;32m    870\u001b[0m     \u001b[39m# Binary mode does not support 'encoding' and 'newline'.\u001b[39;00m\n\u001b[1;32m    871\u001b[0m     \u001b[39mif\u001b[39;00m ioargs\u001b[39m.\u001b[39mencoding \u001b[39mand\u001b[39;00m \u001b[39m\"\u001b[39m\u001b[39mb\u001b[39m\u001b[39m\"\u001b[39m \u001b[39mnot\u001b[39;00m \u001b[39min\u001b[39;00m ioargs\u001b[39m.\u001b[39mmode:\n\u001b[1;32m    872\u001b[0m         \u001b[39m# Encoding\u001b[39;00m\n\u001b[0;32m--> 873\u001b[0m         handle \u001b[39m=\u001b[39m \u001b[39mopen\u001b[39m(\n\u001b[1;32m    874\u001b[0m             handle,\n\u001b[1;32m    875\u001b[0m             ioargs\u001b[39m.\u001b[39mmode,\n\u001b[1;32m    876\u001b[0m             encoding\u001b[39m=\u001b[39mioargs\u001b[39m.\u001b[39mencoding,\n\u001b[1;32m    877\u001b[0m             errors\u001b[39m=\u001b[39merrors,\n\u001b[1;32m    878\u001b[0m             newline\u001b[39m=\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m\"\u001b[39m,\n\u001b[1;32m    879\u001b[0m         )\n\u001b[1;32m    880\u001b[0m     \u001b[39melse\u001b[39;00m:\n\u001b[1;32m    881\u001b[0m         \u001b[39m# Binary mode\u001b[39;00m\n\u001b[1;32m    882\u001b[0m         handle \u001b[39m=\u001b[39m \u001b[39mopen\u001b[39m(handle, ioargs\u001b[39m.\u001b[39mmode)\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'results/cleanup/synthetic_20/synthetic_20_balanced_0.1/LR/x1/fair/preds.csv'"
     ]
    }
   ],
   "source": [
    "# Run Clean up\n",
    "\n",
    "base_path = \"results\"\n",
    "# Run Fair Reduction on every set \n",
    "for exp_name, data_obj in datasets.items():\n",
    "    # if exp_name not in ['synthetic_20_balanced_0.1', 'synthetic_20_balanced_0.3']: continue\n",
    "    # if not name  in ['income_balanced_0.1', 'income_balanced_0.3']: continue \n",
    "    print(exp_name)\n",
    "    eval_labels =  data_obj.eval_labels()\n",
    "    meta = {\"name\": data_obj.name, \"noise\": data_obj.noise_type, \"level\": data_obj.noise_level}\n",
    "    res = []\n",
    "    pred_dict = defaultdict(dict)\n",
    "    for fold, _data in data_obj.foldwise_data.items():\n",
    "        print(fold)\n",
    "        train_data, test_data = _data['train'], _data['test']\n",
    "        x_train, x_test = train_data.drop(data_obj.cols_to_drop, axis = 1, errors='ignore'), test_data.drop(data_obj.cols_to_drop, axis = 1, errors='ignore')\n",
    "        y_train, y_test = train_data[data_obj.label], test_data[data_obj.label]\n",
    "        y_map = {\n",
    "            \"fair\":  data_obj.process_preds(train_data['prob'], 0.5),\n",
    "            \"emp\":  data_obj.process_preds(train_data['emp_prob'], 0.5)\n",
    "        }\n",
    "        sv_train, sv_test = train_data[data_obj.sensitive_attribute], test_data[data_obj.sensitive_attribute]\n",
    "        \n",
    "        for label_type in y_map.keys():\n",
    "            for m_name, clf in model.items():\n",
    "                pred_path = os.path.join(base_path, \"cleanup\", data_obj.name, data_obj.exp_name, m_name, fold, label_type )\n",
    "                pred = pd.read_csv(os.path.join(pred_path, 'preds.csv'))\n",
    "                y_pred = pred['0']\n",
    "\n",
    "                meta['fold'] = fold\n",
    "                meta['model'] = m_name\n",
    "                meta['label_type'] = label_type\n",
    "                for eval_type, _label in eval_labels.items():\n",
    "                    # if eval_type not in ['ground']: continue\n",
    "                    meta['eval_type'] = eval_type\n",
    "                    perf_dict = Metrics().performance_metrics(_label[fold], y_pred, 0.5, meta)\n",
    "                    fair_dict = Metrics().fairness_metrics(_label[fold], y_pred, sv_test, threshold =  0.5, meta = perf_dict)\n",
    "                    print(fair_dict)\n",
    "                    res.append(fair_dict)\n",
    "            save_path = os.path.join(base_path, data_obj.name,data_obj.exp_name)\n",
    "            os.makedirs(save_path, exist_ok=True)\n",
    "            pd.DataFrame(res).to_csv(os.path.join(base_path, data_obj.name,data_obj.exp_name, f\"{label_type}_cleanup.csv\"))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "FL08",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "3d8de94948cdef9a9e8b232b93b0922953996024ad1f8fe36d4a91472f8ef5aa"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
